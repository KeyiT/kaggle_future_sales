{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "from tqdm import tqdm_notebook as tn\n",
    "import gc\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import category_encoders as ce\n",
    "from hyperopt import tpe, fmin, hp, Trials\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../input\"\n",
    "TMP_FOLDER = os.path.join(DATA_FOLDER, \"futuresalepredictiontmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = TMP_FOLDER\n",
    "#FOLDER = SUBMISSION_FOLDER\n",
    "\n",
    "train_data_path = os.path.join(FOLDER, \"train.csv\")\n",
    "test_data_path = os.path.join(FOLDER, \"test.csv\")\n",
    "\n",
    "train_data = pd.read_csv(train_data_path).drop(columns=['month', 'date_block_num'])\n",
    "test_data = pd.read_csv(test_data_path).drop(columns=['month', 'date_block_num'])\n",
    "\n",
    "train_data = downcast_dtypes(train_data)\n",
    "test_data = downcast_dtypes(test_data)\n",
    "\n",
    "print(\"train data shape: \" + str(train_data.shape))\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['target']\n",
    "train_x = train_data.drop(['target'], axis='columns')\n",
    "feature_names = train_x.columns.tolist()\n",
    "\n",
    "if 'target' in test_data.columns.tolist():\n",
    "    test_x = test_data.drop(['target'], axis='columns')\n",
    "    test_y = test_data['target']\n",
    "else:\n",
    "    test_x = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.loc[train_y > 40] = 40\n",
    "if test_y is not None:\n",
    "    test_y.loc[test_y > 40] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'shop_id', 'item_id', 'item_category_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out Encoding\n",
    "categorical_encoder = ce.LeaveOneOutEncoder(cols=categorical_columns, impute_missing=False, drop_invariant=True)\n",
    "categorical_encoder.fit(train_x, train_y)\n",
    "\n",
    "train_x = categorical_encoder.transform(train_x)\n",
    "test_x = categorical_encoder.transform(test_x)\n",
    "\n",
    "train_x = downcast_dtypes(train_x)\n",
    "test_x = downcast_dtypes(test_x)\n",
    "\n",
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.fillna(0, inplace=True)\n",
    "test_x.fillna(0, inplace=True)\n",
    "\n",
    "train_y.fillna(0, inplace=True)\n",
    "test_y.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = RobustScaler()\n",
    "normalizer.fit(train_x)\n",
    "\n",
    "train_x = normalizer.transform(train_x)\n",
    "test_x = normalizer.transform(test_x)\n",
    "\n",
    "# train_y = train_y / 20\n",
    "# if test_y is not None:\n",
    "#     test_y = test_y / 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42)\n",
    "\n",
    "print(\"start training...\")\n",
    "model.fit(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(train_x, train_y), (test_x, test_y)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 10)\n",
    "\n",
    "pred_train_y = model.predict(train_x)\n",
    "print('Train R-squared for XGBoost is %f' % r2_score(train_y, pred_y))\n",
    "    \n",
    "pred_test_y = model.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_tmp = train_y.copy()\n",
    "test_y_tmp = test_y.copy()\n",
    "\n",
    "train_y_tmp[train_y_tmp>20] = 20.0\n",
    "pred_train_y[pred_train_y>20] = 20.0 \n",
    "print('Train R-squared for XGBoost is %f' % r2_score(train_y_tmp, pred_train_y))\n",
    "print('Train msre is: ' + str(sqrt(mean_squared_error(train_y_tmp, pred_train_y))))\n",
    "\n",
    "if test_y is not None:\n",
    "    test_y_tmp[test_y_tmp>20] = 20.0\n",
    "    pred_test_y[pred_test_y>20] = 20.0 \n",
    "    print('Test R-squared for XGBoost is %f' % r2_score(test_y_tmp, pred_test_y))\n",
    "    print('Test msre is: ' + str(sqrt(mean_squared_error(test_y_tmp, pred_test_y))))\n",
    "    \n",
    "del train_y_tmp, test_y_tmp\n",
    "gc.collect();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
