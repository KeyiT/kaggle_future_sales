{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyitang/miniconda3/envs/kaggleFutureSales/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "from tqdm import tqdm_notebook as tn\n",
    "import gc\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import category_encoders as ce\n",
    "from hyperopt import tpe, fmin, hp, Trials\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../input\"\n",
    "TMP_FOLDER = os.path.join(DATA_FOLDER, \"futuresalepredictiontmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (6186922, 88)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "item_category_id                         int32\n",
       "shop_id                                  int32\n",
       "item_id                                  int32\n",
       "target                                 float32\n",
       "shop_id_count_month_lag_1              float32\n",
       "shop_id_sale_month_lag_1               float32\n",
       "item_id_count_month_lag_1              float32\n",
       "item_id_sale_month_lag_1               float32\n",
       "item_price_mean_month_lag_1            float32\n",
       "item_price_std_month_lag_1             float32\n",
       "item_shop_cnt_sum_month_lag_1          float32\n",
       "item_shop_cnt_std_month_lag_1          float32\n",
       "item_shop_sale_sum_month_lag_1         float32\n",
       "item_shop_sale_std_month_lag_1         float32\n",
       "item_category_id_count_month_lag_1     float32\n",
       "item_category_id_sale_month_lag_1      float32\n",
       "shop_id_count_month_lag_2              float32\n",
       "shop_id_sale_month_lag_2               float32\n",
       "item_id_count_month_lag_2              float32\n",
       "item_id_sale_month_lag_2               float32\n",
       "item_price_mean_month_lag_2            float32\n",
       "item_price_std_month_lag_2             float32\n",
       "item_shop_cnt_sum_month_lag_2          float32\n",
       "item_shop_cnt_std_month_lag_2          float32\n",
       "item_shop_sale_sum_month_lag_2         float32\n",
       "item_shop_sale_std_month_lag_2         float32\n",
       "item_category_id_count_month_lag_2     float32\n",
       "item_category_id_sale_month_lag_2      float32\n",
       "shop_id_count_month_lag_3              float32\n",
       "shop_id_sale_month_lag_3               float32\n",
       "                                        ...   \n",
       "item_shop_cnt_sum_month_lag_5          float32\n",
       "item_shop_cnt_std_month_lag_5          float32\n",
       "item_shop_sale_sum_month_lag_5         float32\n",
       "item_shop_sale_std_month_lag_5         float32\n",
       "item_category_id_count_month_lag_5     float32\n",
       "item_category_id_sale_month_lag_5      float32\n",
       "shop_id_count_month_lag_6              float32\n",
       "shop_id_sale_month_lag_6               float32\n",
       "item_id_count_month_lag_6              float32\n",
       "item_id_sale_month_lag_6               float32\n",
       "item_price_mean_month_lag_6            float32\n",
       "item_price_std_month_lag_6             float32\n",
       "item_shop_cnt_sum_month_lag_6          float32\n",
       "item_shop_cnt_std_month_lag_6          float32\n",
       "item_shop_sale_sum_month_lag_6         float32\n",
       "item_shop_sale_std_month_lag_6         float32\n",
       "item_category_id_count_month_lag_6     float32\n",
       "item_category_id_sale_month_lag_6      float32\n",
       "shop_id_count_month_lag_12             float32\n",
       "shop_id_sale_month_lag_12              float32\n",
       "item_id_count_month_lag_12             float32\n",
       "item_id_sale_month_lag_12              float32\n",
       "item_price_mean_month_lag_12           float32\n",
       "item_price_std_month_lag_12            float32\n",
       "item_shop_cnt_sum_month_lag_12         float32\n",
       "item_shop_cnt_std_month_lag_12         float32\n",
       "item_shop_sale_sum_month_lag_12        float32\n",
       "item_shop_sale_std_month_lag_12        float32\n",
       "item_category_id_count_month_lag_12    float32\n",
       "item_category_id_sale_month_lag_12     float32\n",
       "Length: 88, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = TMP_FOLDER\n",
    "#FOLDER = SUBMISSION_FOLDER\n",
    "\n",
    "train_data_path = os.path.join(FOLDER, \"train.csv\")\n",
    "test_data_path = os.path.join(FOLDER, \"test.csv\")\n",
    "\n",
    "train_data = pd.read_csv(train_data_path).drop(columns=['month', 'date_block_num'])\n",
    "test_data = pd.read_csv(test_data_path).drop(columns=['month', 'date_block_num'])\n",
    "\n",
    "train_data = downcast_dtypes(train_data)\n",
    "test_data = downcast_dtypes(test_data)\n",
    "\n",
    "print(\"train data shape: \" + str(train_data.shape))\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['target']\n",
    "train_x = train_data.drop(['target'], axis='columns')\n",
    "feature_names = train_x.columns.tolist()\n",
    "\n",
    "if 'target' in test_data.columns.tolist():\n",
    "    test_x = test_data.drop(['target'], axis='columns')\n",
    "    test_y = test_data['target']\n",
    "else:\n",
    "    test_x = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyitang/miniconda3/envs/kaggleFutureSales/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "train_y.loc[train_y > 40] = 40\n",
    "if test_y is not None:\n",
    "    test_y.loc[test_y > 40] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'shop_id', 'item_id', 'item_category_id'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_category_id                       float32\n",
       "shop_id                                float32\n",
       "item_id                                float32\n",
       "shop_id_count_month_lag_1              float32\n",
       "shop_id_sale_month_lag_1               float32\n",
       "item_id_count_month_lag_1              float32\n",
       "item_id_sale_month_lag_1               float32\n",
       "item_price_mean_month_lag_1            float32\n",
       "item_price_std_month_lag_1             float32\n",
       "item_shop_cnt_sum_month_lag_1          float32\n",
       "item_shop_cnt_std_month_lag_1          float32\n",
       "item_shop_sale_sum_month_lag_1         float32\n",
       "item_shop_sale_std_month_lag_1         float32\n",
       "item_category_id_count_month_lag_1     float32\n",
       "item_category_id_sale_month_lag_1      float32\n",
       "shop_id_count_month_lag_2              float32\n",
       "shop_id_sale_month_lag_2               float32\n",
       "item_id_count_month_lag_2              float32\n",
       "item_id_sale_month_lag_2               float32\n",
       "item_price_mean_month_lag_2            float32\n",
       "item_price_std_month_lag_2             float32\n",
       "item_shop_cnt_sum_month_lag_2          float32\n",
       "item_shop_cnt_std_month_lag_2          float32\n",
       "item_shop_sale_sum_month_lag_2         float32\n",
       "item_shop_sale_std_month_lag_2         float32\n",
       "item_category_id_count_month_lag_2     float32\n",
       "item_category_id_sale_month_lag_2      float32\n",
       "shop_id_count_month_lag_3              float32\n",
       "shop_id_sale_month_lag_3               float32\n",
       "item_id_count_month_lag_3              float32\n",
       "                                        ...   \n",
       "item_shop_cnt_sum_month_lag_5          float32\n",
       "item_shop_cnt_std_month_lag_5          float32\n",
       "item_shop_sale_sum_month_lag_5         float32\n",
       "item_shop_sale_std_month_lag_5         float32\n",
       "item_category_id_count_month_lag_5     float32\n",
       "item_category_id_sale_month_lag_5      float32\n",
       "shop_id_count_month_lag_6              float32\n",
       "shop_id_sale_month_lag_6               float32\n",
       "item_id_count_month_lag_6              float32\n",
       "item_id_sale_month_lag_6               float32\n",
       "item_price_mean_month_lag_6            float32\n",
       "item_price_std_month_lag_6             float32\n",
       "item_shop_cnt_sum_month_lag_6          float32\n",
       "item_shop_cnt_std_month_lag_6          float32\n",
       "item_shop_sale_sum_month_lag_6         float32\n",
       "item_shop_sale_std_month_lag_6         float32\n",
       "item_category_id_count_month_lag_6     float32\n",
       "item_category_id_sale_month_lag_6      float32\n",
       "shop_id_count_month_lag_12             float32\n",
       "shop_id_sale_month_lag_12              float32\n",
       "item_id_count_month_lag_12             float32\n",
       "item_id_sale_month_lag_12              float32\n",
       "item_price_mean_month_lag_12           float32\n",
       "item_price_std_month_lag_12            float32\n",
       "item_shop_cnt_sum_month_lag_12         float32\n",
       "item_shop_cnt_std_month_lag_12         float32\n",
       "item_shop_sale_sum_month_lag_12        float32\n",
       "item_shop_sale_std_month_lag_12        float32\n",
       "item_category_id_count_month_lag_12    float32\n",
       "item_category_id_sale_month_lag_12     float32\n",
       "Length: 87, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave-One-Out Encoding\n",
    "categorical_encoder = ce.LeaveOneOutEncoder(cols=categorical_columns, impute_missing=False, drop_invariant=True)\n",
    "categorical_encoder.fit(train_x, train_y)\n",
    "\n",
    "train_x = categorical_encoder.transform(train_x)\n",
    "test_x = categorical_encoder.transform(test_x)\n",
    "\n",
    "train_x = downcast_dtypes(train_x)\n",
    "test_x = downcast_dtypes(test_x)\n",
    "\n",
    "train_x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.fillna(0, inplace=True)\n",
    "test_x.fillna(0, inplace=True)\n",
    "\n",
    "train_y.fillna(0, inplace=True)\n",
    "test_y.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = RobustScaler()\n",
    "normalizer.fit(train_x)\n",
    "\n",
    "train_x = normalizer.transform(train_x)\n",
    "test_x = normalizer.transform(test_x)\n",
    "\n",
    "# train_y = train_y / 20\n",
    "# if test_y is not None:\n",
    "#     test_y = test_y / 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':3, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "\n",
    "lgb_dataset = lgb.Dataset(train_x, label=train_y)\n",
    "\n",
    "print(\"start training...\")\n",
    "model = lgb.train(lgb_params, lgb_dataset, 100)\n",
    "\n",
    "pred_train_y = model.predict(train_x)\n",
    "#print('Train R-squared for LightGBM is %f' % r2_score(train_y, pred_y))\n",
    "    \n",
    "pred_test_y = model.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for LightGBM is 0.460630\n",
      "Train msre is: 0.8726989153191355\n",
      "Test R-squared for LightGBM is 0.139518\n",
      "Test msre is: 1.0539477867028537\n"
     ]
    }
   ],
   "source": [
    "train_y_tmp = train_y.copy()\n",
    "test_y_tmp = test_y.copy()\n",
    "\n",
    "train_y_tmp[train_y_tmp>20] = 20.0\n",
    "pred_train_y[pred_train_y>20] = 20.0 \n",
    "print('Train R-squared for LightGBM is %f' % r2_score(train_y_tmp, pred_train_y))\n",
    "print('Train msre is: ' + str(sqrt(mean_squared_error(train_y_tmp, pred_train_y))))\n",
    "\n",
    "if test_y is not None:\n",
    "    test_y_tmp[test_y_tmp>20] = 20.0\n",
    "    pred_test_y[pred_test_y>20] = 20.0 \n",
    "    print('Test R-squared for LightGBM is %f' % r2_score(test_y_tmp, pred_test_y))\n",
    "    print('Test msre is: ' + str(sqrt(mean_squared_error(test_y_tmp, pred_test_y))))\n",
    "    \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    {\n",
    "        'feature_name': feature_names,\n",
    "        'feature_importance': model.feature_importance().tolist()\n",
    "    }\n",
    ")\n",
    "\n",
    "feature_importances.sort_values('feature_importance', ascending=False, inplace=True)\n",
    "important_feature_names = set(feature_importances[:30]['feature_name'].tolist())\n",
    "\n",
    "important_feature_names\n",
    "\n",
    "feature_boolean_mask = np.asarray(list(\n",
    "    map(\n",
    "        lambda feature_name: feature_name in important_feature_names,\n",
    "        feature_names\n",
    "    )\n",
    "))\n",
    "\n",
    "train_x = train_x[:, feature_boolean_mask]\n",
    "test_x = test_x[:, feature_boolean_mask]\n",
    "\n",
    "lgb_dataset = lgb.Dataset(train_x, label=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, train_x\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred_list = list()\n",
    "def objective(hyper_param):\n",
    "    \n",
    "    print(\"hyper_params: \" + str(hyper_param))\n",
    "    max_depth, num_leaves, min_data_in_leaf = hyper_param\n",
    "    \n",
    "    lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':3, \n",
    "               'min_data_in_leaf': int(min_data_in_leaf), \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': int(num_leaves),\n",
    "               'max_depth': int(max_depth),\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0 \n",
    "              }\n",
    "    print(\"start training...\" + str(len(test_y_pred_list)))\n",
    "    model = lgb.train(lgb_params, lgb_dataset, 100)\n",
    "    pred_test_y = model.predict(test_x)\n",
    "    \n",
    "    pred_test_y[pred_test_y>20] = 20.0 \n",
    "    result = sqrt(mean_squared_error(test_y_tmp, pred_test_y))\n",
    "    test_y_pred_list.append(pred_test_y)\n",
    "    \n",
    "    gc.collect();\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# tuning algorithm\n",
    "tpe_algo = tpe.suggest\n",
    "\n",
    "# search space\n",
    "space = [\n",
    "    hp.quniform('max_depth', 5, 10, 1),\n",
    "    hp.quniform('num_leaves', 2**5, 2**10, 5),\n",
    "    hp.quniform('min_data_in_leaf', 2**5, 10**4, 5)\n",
    "]\n",
    "\n",
    "# history\n",
    "tpe_trials = Trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyper_params: (8.0, 1020.0, 5860.0)\n",
      "start training...0\n",
      "hyper_params: (8.0, 885.0, 4530.0)\n",
      "start training...1\n",
      "hyper_params: (9.0, 775.0, 9835.0)\n",
      "start training...2\n",
      "hyper_params: (7.0, 435.0, 655.0)\n",
      "start training...3\n",
      "hyper_params: (6.0, 40.0, 8950.0)\n",
      "start training...4\n",
      "hyper_params: (6.0, 405.0, 4390.0)\n",
      "start training...5\n",
      "hyper_params: (9.0, 660.0, 3755.0)\n",
      "start training...6\n",
      "hyper_params: (7.0, 305.0, 7800.0)\n",
      "start training...7\n",
      "hyper_params: (9.0, 555.0, 4425.0)\n",
      "start training...8\n",
      "hyper_params: (9.0, 775.0, 5535.0)\n",
      "start training...9\n",
      "hyper_params: (6.0, 585.0, 7245.0)\n",
      "start training...10\n",
      "hyper_params: (6.0, 835.0, 200.0)\n",
      "start training...11\n",
      "hyper_params: (10.0, 130.0, 2365.0)\n",
      "start training...12\n",
      "hyper_params: (6.0, 670.0, 6905.0)\n",
      "start training...13\n",
      "hyper_params: (7.0, 950.0, 4545.0)\n",
      "start training...14\n",
      "hyper_params: (5.0, 355.0, 7075.0)\n",
      "start training...15\n",
      "hyper_params: (7.0, 85.0, 5785.0)\n",
      "start training...16\n",
      "hyper_params: (10.0, 195.0, 9615.0)\n",
      "start training...17\n",
      "hyper_params: (5.0, 565.0, 975.0)\n",
      "start training...18\n",
      "hyper_params: (9.0, 1000.0, 5870.0)\n",
      "start training...19\n",
      "hyper_params: (7.0, 445.0, 80.0)\n",
      "start training...20\n",
      "hyper_params: (5.0, 255.0, 1395.0)\n",
      "start training...21\n",
      "hyper_params: (8.0, 460.0, 90.0)\n",
      "start training...22\n",
      "hyper_params: (6.0, 810.0, 2730.0)\n",
      "start training...23\n",
      "hyper_params: (7.0, 650.0, 1110.0)\n",
      "start training...24\n",
      "hyper_params: (5.0, 485.0, 2180.0)\n",
      "start training...25\n",
      "hyper_params: (6.0, 860.0, 3460.0)\n",
      "start training...26\n",
      "hyper_params: (8.0, 730.0, 520.0)\n",
      "start training...27\n",
      "hyper_params: (8.0, 345.0, 1740.0)\n",
      "start training...28\n",
      "hyper_params: (7.0, 990.0, 55.0)\n",
      "start training...29\n",
      "hyper_params: (6.0, 905.0, 3040.0)\n",
      "start training...30\n",
      "hyper_params: (5.0, 615.0, 1860.0)\n",
      "start training...31\n",
      "hyper_params: (7.0, 510.0, 780.0)\n",
      "start training...32\n",
      "hyper_params: (8.0, 515.0, 3725.0)\n",
      "start training...33\n",
      "hyper_params: (6.0, 735.0, 665.0)\n",
      "start training...34\n",
      "hyper_params: (5.0, 735.0, 1510.0)\n",
      "start training...35\n",
      "hyper_params: (6.0, 880.0, 8515.0)\n",
      "start training...36\n",
      "hyper_params: (5.0, 815.0, 2865.0)\n",
      "start training...37\n",
      "hyper_params: (6.0, 700.0, 425.0)\n",
      "start training...38\n",
      "hyper_params: (6.0, 710.0, 4875.0)\n",
      "start training...39\n",
      "hyper_params: (5.0, 930.0, 6240.0)\n",
      "start training...40\n",
      "hyper_params: (6.0, 835.0, 4020.0)\n",
      "start training...41\n",
      "hyper_params: (7.0, 780.0, 2145.0)\n",
      "start training...42\n",
      "hyper_params: (6.0, 680.0, 355.0)\n",
      "start training...43\n",
      "hyper_params: (5.0, 620.0, 3385.0)\n",
      "start training...44\n",
      "hyper_params: (7.0, 965.0, 2485.0)\n",
      "start training...45\n",
      "hyper_params: (8.0, 1015.0, 5250.0)\n",
      "start training...46\n",
      "hyper_params: (6.0, 400.0, 8635.0)\n",
      "start training...47\n",
      "hyper_params: (9.0, 775.0, 6435.0)\n",
      "start training...48\n",
      "hyper_params: (7.0, 910.0, 1225.0)\n",
      "start training...49\n",
      "hyper_params: (5.0, 580.0, 9955.0)\n",
      "start training...50\n",
      "hyper_params: (10.0, 850.0, 4245.0)\n",
      "start training...51\n",
      "hyper_params: (6.0, 695.0, 7645.0)\n",
      "start training...52\n",
      "hyper_params: (5.0, 545.0, 9485.0)\n",
      "start training...53\n",
      "hyper_params: (8.0, 635.0, 4815.0)\n",
      "start training...54\n",
      "hyper_params: (6.0, 400.0, 310.0)\n",
      "start training...55\n",
      "hyper_params: (7.0, 960.0, 1690.0)\n",
      "start training...56\n",
      "hyper_params: (6.0, 35.0, 1010.0)\n",
      "start training...57\n",
      "hyper_params: (5.0, 220.0, 3230.0)\n",
      "start training...58\n",
      "hyper_params: (7.0, 775.0, 2650.0)\n",
      "start training...59\n",
      "hyper_params: (9.0, 605.0, 3740.0)\n",
      "start training...60\n",
      "hyper_params: (6.0, 290.0, 2295.0)\n",
      "start training...61\n",
      "hyper_params: (8.0, 885.0, 1940.0)\n",
      "start training...62\n",
      "hyper_params: (5.0, 810.0, 5435.0)\n",
      "start training...63\n",
      "hyper_params: (7.0, 660.0, 65.0)\n",
      "start training...64\n",
      "hyper_params: (6.0, 735.0, 725.0)\n",
      "start training...65\n",
      "hyper_params: (6.0, 745.0, 1385.0)\n",
      "start training...66\n",
      "hyper_params: (6.0, 475.0, 535.0)\n",
      "start training...67\n",
      "hyper_params: (5.0, 135.0, 950.0)\n",
      "start training...68\n",
      "hyper_params: (5.0, 425.0, 395.0)\n",
      "start training...69\n",
      "hyper_params: (7.0, 500.0, 1505.0)\n",
      "start training...70\n",
      "hyper_params: (6.0, 345.0, 2030.0)\n",
      "start training...71\n",
      "hyper_params: (7.0, 465.0, 1215.0)\n",
      "start training...72\n",
      "hyper_params: (5.0, 580.0, 3055.0)\n",
      "start training...73\n",
      "hyper_params: (6.0, 315.0, 75.0)\n",
      "start training...74\n",
      "hyper_params: (6.0, 555.0, 490.0)\n",
      "start training...75\n",
      "hyper_params: (5.0, 550.0, 2470.0)\n",
      "start training...76\n",
      "hyper_params: (6.0, 380.0, 730.0)\n",
      "start training...77\n",
      "hyper_params: (7.0, 475.0, 535.0)\n",
      "start training...78\n",
      "hyper_params: (6.0, 435.0, 1600.0)\n",
      "start training...79\n",
      "hyper_params: (5.0, 535.0, 3965.0)\n",
      "start training...80\n",
      "hyper_params: (7.0, 600.0, 6645.0)\n",
      "start training...81\n",
      "hyper_params: (6.0, 260.0, 5965.0)\n",
      "start training...82\n",
      "hyper_params: (5.0, 365.0, 2880.0)\n",
      "start training...83\n",
      "hyper_params: (6.0, 155.0, 4630.0)\n",
      "start training...84\n",
      "hyper_params: (7.0, 685.0, 3490.0)\n",
      "start training...85\n",
      "hyper_params: (6.0, 640.0, 870.0)\n",
      "start training...86\n",
      "hyper_params: (5.0, 490.0, 1835.0)\n",
      "start training...87\n",
      "hyper_params: (8.0, 520.0, 8030.0)\n",
      "start training...88\n",
      "hyper_params: (7.0, 710.0, 1260.0)\n",
      "start training...89\n",
      "hyper_params: (6.0, 565.0, 520.0)\n",
      "start training...90\n",
      "hyper_params: (6.0, 450.0, 250.0)\n",
      "start training...91\n",
      "hyper_params: (5.0, 315.0, 2595.0)\n",
      "start training...92\n",
      "hyper_params: (10.0, 565.0, 570.0)\n",
      "start training...93\n",
      "hyper_params: (8.0, 75.0, 2185.0)\n",
      "start training...94\n",
      "hyper_params: (7.0, 185.0, 4215.0)\n",
      "start training...95\n",
      "hyper_params: (5.0, 415.0, 5135.0)\n",
      "start training...96\n",
      "hyper_params: (6.0, 260.0, 1370.0)\n",
      "start training...97\n",
      "hyper_params: (9.0, 385.0, 1065.0)\n",
      "start training...98\n",
      "hyper_params: (5.0, 665.0, 1725.0)\n",
      "start training...99\n",
      "{'max_depth': 6.0, 'min_data_in_leaf': 490.0, 'num_leaves': 555.0}\n"
     ]
    }
   ],
   "source": [
    "# Run 2000 evals with the tpe algorithm\n",
    "tpe_best = fmin(fn=objective, space=space, algo=tpe_algo, trials=tpe_trials, max_evals=100, rstate= np.random.RandomState(50))\n",
    "\n",
    "print(tpe_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.asarray(list(map(\n",
    "    lambda trial_result: trial_result['loss'],\n",
    "    tpe_trials.results\n",
    ")))\n",
    "pred_ys = np.asarray(test_y_pred_list)\n",
    "\n",
    "indices = np.argsort(losses)\n",
    "losses_sorted = losses[indices]\n",
    "pred_ys_soretd = pred_ys[indices, :]\n",
    "pred_ys_sorted = pred_ys_soretd[0:5, :].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test msre is: 1.0265782761097844\n"
     ]
    }
   ],
   "source": [
    "test_y_pred_agg = np.zeros(shape=test_y.shape)\n",
    "for test_y_pred in pred_ys_sorted:\n",
    "    test_y_pred_agg += np.asarray(test_y_pred)\n",
    "test_y_pred_agg /= len(pred_ys_sorted)\n",
    "\n",
    "print('Test msre is: ' + str(sqrt(mean_squared_error(test_y_tmp, test_y_pred_agg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 1.0558229477326573, 'status': 'ok'},\n",
       " {'loss': 1.0583271782471553, 'status': 'ok'},\n",
       " {'loss': 1.0574323928972862, 'status': 'ok'},\n",
       " {'loss': 1.031782203751633, 'status': 'ok'},\n",
       " {'loss': 1.059645805966958, 'status': 'ok'},\n",
       " {'loss': 1.0632516446551346, 'status': 'ok'},\n",
       " {'loss': 1.0558374707251503, 'status': 'ok'},\n",
       " {'loss': 1.0594748586785376, 'status': 'ok'},\n",
       " {'loss': 1.0563795126476294, 'status': 'ok'},\n",
       " {'loss': 1.055948506750416, 'status': 'ok'},\n",
       " {'loss': 1.0615185174700679, 'status': 'ok'},\n",
       " {'loss': 1.0293080718667411, 'status': 'ok'},\n",
       " {'loss': 1.0454800124655141, 'status': 'ok'},\n",
       " {'loss': 1.0561078045876906, 'status': 'ok'},\n",
       " {'loss': 1.0576964920493244, 'status': 'ok'},\n",
       " {'loss': 1.0622568725319321, 'status': 'ok'},\n",
       " {'loss': 1.0569191212396443, 'status': 'ok'},\n",
       " {'loss': 1.056333146990011, 'status': 'ok'},\n",
       " {'loss': 1.0319578831635274, 'status': 'ok'},\n",
       " {'loss': 1.057057118322009, 'status': 'ok'},\n",
       " {'loss': 1.040620873955733, 'status': 'ok'},\n",
       " {'loss': 1.0483360587166708, 'status': 'ok'},\n",
       " {'loss': 1.0475615460972578, 'status': 'ok'},\n",
       " {'loss': 1.0525249112341373, 'status': 'ok'},\n",
       " {'loss': 1.041749407712091, 'status': 'ok'},\n",
       " {'loss': 1.056174818791502, 'status': 'ok'},\n",
       " {'loss': 1.0546244765792916, 'status': 'ok'},\n",
       " {'loss': 1.0322689483778453, 'status': 'ok'},\n",
       " {'loss': 1.0409228079965527, 'status': 'ok'},\n",
       " {'loss': 1.0446390518963535, 'status': 'ok'},\n",
       " {'loss': 1.0524246159949868, 'status': 'ok'},\n",
       " {'loss': 1.0539228011172945, 'status': 'ok'},\n",
       " {'loss': 1.0311740607131152, 'status': 'ok'},\n",
       " {'loss': 1.055239812380279, 'status': 'ok'},\n",
       " {'loss': 1.0293301790920653, 'status': 'ok'},\n",
       " {'loss': 1.0511790181234917, 'status': 'ok'},\n",
       " {'loss': 1.060053192525727, 'status': 'ok'},\n",
       " {'loss': 1.0635896751979244, 'status': 'ok'},\n",
       " {'loss': 1.0275067294554887, 'status': 'ok'},\n",
       " {'loss': 1.0584749199632042, 'status': 'ok'},\n",
       " {'loss': 1.0595613098600598, 'status': 'ok'},\n",
       " {'loss': 1.0593507549570367, 'status': 'ok'},\n",
       " {'loss': 1.0458759797248944, 'status': 'ok'},\n",
       " {'loss': 1.0323549284909272, 'status': 'ok'},\n",
       " {'loss': 1.0593395286715086, 'status': 'ok'},\n",
       " {'loss': 1.0466500307783808, 'status': 'ok'},\n",
       " {'loss': 1.0576005506870605, 'status': 'ok'},\n",
       " {'loss': 1.06185167903548, 'status': 'ok'},\n",
       " {'loss': 1.0538059378746676, 'status': 'ok'},\n",
       " {'loss': 1.040729450097415, 'status': 'ok'},\n",
       " {'loss': 1.0633508659485829, 'status': 'ok'},\n",
       " {'loss': 1.0569553525817095, 'status': 'ok'},\n",
       " {'loss': 1.0595716033461062, 'status': 'ok'},\n",
       " {'loss': 1.060460171216376, 'status': 'ok'},\n",
       " {'loss': 1.0550922040098643, 'status': 'ok'},\n",
       " {'loss': 1.0296787845248412, 'status': 'ok'},\n",
       " {'loss': 1.0385843208374586, 'status': 'ok'},\n",
       " {'loss': 1.0325953865122908, 'status': 'ok'},\n",
       " {'loss': 1.0597799018450622, 'status': 'ok'},\n",
       " {'loss': 1.0493007929042044, 'status': 'ok'},\n",
       " {'loss': 1.0529522199797265, 'status': 'ok'},\n",
       " {'loss': 1.0485310852551148, 'status': 'ok'},\n",
       " {'loss': 1.0469728394915825, 'status': 'ok'},\n",
       " {'loss': 1.0627836690659838, 'status': 'ok'},\n",
       " {'loss': 1.0397480947834847, 'status': 'ok'},\n",
       " {'loss': 1.0314790450420865, 'status': 'ok'},\n",
       " {'loss': 1.0432599203246398, 'status': 'ok'},\n",
       " {'loss': 1.026482260205709, 'status': 'ok'},\n",
       " {'loss': 1.0312053779913815, 'status': 'ok'},\n",
       " {'loss': 1.0311966715168672, 'status': 'ok'},\n",
       " {'loss': 1.0434827160301745, 'status': 'ok'},\n",
       " {'loss': 1.0475455720370612, 'status': 'ok'},\n",
       " {'loss': 1.0414641822152422, 'status': 'ok'},\n",
       " {'loss': 1.061908510847367, 'status': 'ok'},\n",
       " {'loss': 1.0411750919006295, 'status': 'ok'},\n",
       " {'loss': 1.0253205230526556, 'status': 'ok'},\n",
       " {'loss': 1.0597248033578197, 'status': 'ok'},\n",
       " {'loss': 1.031398995927342, 'status': 'ok'},\n",
       " {'loss': 1.0303517599342116, 'status': 'ok'},\n",
       " {'loss': 1.0450087728050792, 'status': 'ok'},\n",
       " {'loss': 1.066991962331882, 'status': 'ok'},\n",
       " {'loss': 1.0534300490237454, 'status': 'ok'},\n",
       " {'loss': 1.058232441401902, 'status': 'ok'},\n",
       " {'loss': 1.0642809038862222, 'status': 'ok'},\n",
       " {'loss': 1.0595146556025188, 'status': 'ok'},\n",
       " {'loss': 1.0531258832023846, 'status': 'ok'},\n",
       " {'loss': 1.0320727891175154, 'status': 'ok'},\n",
       " {'loss': 1.0553914527581838, 'status': 'ok'},\n",
       " {'loss': 1.0555760095930715, 'status': 'ok'},\n",
       " {'loss': 1.0407432474067524, 'status': 'ok'},\n",
       " {'loss': 1.0260803423297449, 'status': 'ok'},\n",
       " {'loss': 1.0313726511452093, 'status': 'ok'},\n",
       " {'loss': 1.0567701893818147, 'status': 'ok'},\n",
       " {'loss': 1.0337736813168166, 'status': 'ok'},\n",
       " {'loss': 1.0448452060259101, 'status': 'ok'},\n",
       " {'loss': 1.0596577865436116, 'status': 'ok'},\n",
       " {'loss': 1.0615229086643458, 'status': 'ok'},\n",
       " {'loss': 1.041194815351759, 'status': 'ok'},\n",
       " {'loss': 1.0411310025074512, 'status': 'ok'},\n",
       " {'loss': 1.0587724238133063, 'status': 'ok'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpe_trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lgb_params = {\n",
    "#                'feature_fraction': 0.75,\n",
    "#                'metric': 'rmse',\n",
    "#                'nthread':1, \n",
    "#                'min_data_in_leaf': 2**7, \n",
    "#                'bagging_fraction': 0.75, \n",
    "#                'learning_rate': 0.03, \n",
    "#                'objective': 'mse', \n",
    "#                'bagging_seed': 2**7, \n",
    "#                'num_leaves': 2**6,\n",
    "#                'bagging_freq':1,\n",
    "#                'verbose':0 \n",
    "#               }\n",
    "# model = lgb.train(lgb_params, lgb.Dataset(train_x, label=train_y), 100)\n",
    "\n",
    "# pred_y = model.predict(train_x)\n",
    "# print('Train R-squared for LightGBM is %f' % r2_score(train_y, pred_y))\n",
    "    \n",
    "# pred_y = model.predict(test_x)\n",
    "# if test_y is not None:\n",
    "#     print('Test R-squared for LightGBM is %f' % r2_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt(mean_squared_error(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearRegression().fit(train_x, train_y)\n",
    "\n",
    "# pred_y = model.predict(train_x)\n",
    "# print('Train R-squared for LinearRegression is %f' % r2_score(train_y, pred_y))\n",
    "    \n",
    "# pred_y = model.predict(test_x)\n",
    "# if test_y is not None:\n",
    "#     print('Test R-squared for LinearRegression is %f' % r2_score(test_y, pred_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqrt(mean_squared_error(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
